{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "eng_to_hindi_transliteration_TF-Final.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghQPCyJcxogq",
        "colab_type": "text"
      },
      "source": [
        "## Neural machine transliteration using attention.\n",
        "#### Using tensorflow 2.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmzXCECjx2cy",
        "colab_type": "text"
      },
      "source": [
        "### Mounting the google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UbeF3vZe9doq",
        "colab_type": "code",
        "outputId": "b3d06bbd-4bf9-42ce-f10b-e8445f3fc259",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HWcjGompyATi",
        "colab_type": "text"
      },
      "source": [
        "### Imports."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26nlHSvW90rw",
        "colab_type": "code",
        "outputId": "42efd7c4-865f-454e-c089-be2ccff3c2cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "from __future__ import absolute_import, division, print_function\n",
        "\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "import os\n",
        "import io\n",
        "import time\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import unicodedata\n",
        "import re\n",
        "import time\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n",
            "2.0.0-rc0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CE3wZTs6iqM_",
        "colab_type": "text"
      },
      "source": [
        "### Storing some hindi alphabets for text pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n628FEbV0MtQ",
        "colab_type": "code",
        "outputId": "1ea556c5-7596-4e94-b832-a67d318c8d62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "hindi_alphabets = [chr(alpha) for alpha in range(2304, 2432)]\n",
        "hindi_alphabet_size = len(hindi_alphabets)\n",
        "\n",
        "hindi_alpha2index = {'<start>': 0,'<end>' : 1}\n",
        "for index, alpha in enumerate(hindi_alphabets):\n",
        "    hindi_alpha2index[alpha] = index+1\n",
        "\n",
        "print(hindi_alpha2index)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'<start>': 0, '<end>': 1, 'ऀ': 1, 'ँ': 2, 'ं': 3, 'ः': 4, 'ऄ': 5, 'अ': 6, 'आ': 7, 'इ': 8, 'ई': 9, 'उ': 10, 'ऊ': 11, 'ऋ': 12, 'ऌ': 13, 'ऍ': 14, 'ऎ': 15, 'ए': 16, 'ऐ': 17, 'ऑ': 18, 'ऒ': 19, 'ओ': 20, 'औ': 21, 'क': 22, 'ख': 23, 'ग': 24, 'घ': 25, 'ङ': 26, 'च': 27, 'छ': 28, 'ज': 29, 'झ': 30, 'ञ': 31, 'ट': 32, 'ठ': 33, 'ड': 34, 'ढ': 35, 'ण': 36, 'त': 37, 'थ': 38, 'द': 39, 'ध': 40, 'न': 41, 'ऩ': 42, 'प': 43, 'फ': 44, 'ब': 45, 'भ': 46, 'म': 47, 'य': 48, 'र': 49, 'ऱ': 50, 'ल': 51, 'ळ': 52, 'ऴ': 53, 'व': 54, 'श': 55, 'ष': 56, 'स': 57, 'ह': 58, 'ऺ': 59, 'ऻ': 60, '़': 61, 'ऽ': 62, 'ा': 63, 'ि': 64, 'ी': 65, 'ु': 66, 'ू': 67, 'ृ': 68, 'ॄ': 69, 'ॅ': 70, 'ॆ': 71, 'े': 72, 'ै': 73, 'ॉ': 74, 'ॊ': 75, 'ो': 76, 'ौ': 77, '्': 78, 'ॎ': 79, 'ॏ': 80, 'ॐ': 81, '॑': 82, '॒': 83, '॓': 84, '॔': 85, 'ॕ': 86, 'ॖ': 87, 'ॗ': 88, 'क़': 89, 'ख़': 90, 'ग़': 91, 'ज़': 92, 'ड़': 93, 'ढ़': 94, 'फ़': 95, 'य़': 96, 'ॠ': 97, 'ॡ': 98, 'ॢ': 99, 'ॣ': 100, '।': 101, '॥': 102, '०': 103, '१': 104, '२': 105, '३': 106, '४': 107, '५': 108, '६': 109, '७': 110, '८': 111, '९': 112, '॰': 113, 'ॱ': 114, 'ॲ': 115, 'ॳ': 116, 'ॴ': 117, 'ॵ': 118, 'ॶ': 119, 'ॷ': 120, 'ॸ': 121, 'ॹ': 122, 'ॺ': 123, 'ॻ': 124, 'ॼ': 125, 'ॽ': 126, 'ॾ': 127, 'ॿ': 128}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xF9xKDFyyLnL",
        "colab_type": "text"
      },
      "source": [
        "### Some pre-processing helper functions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8iYg16lyq3Wu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def unicode_to_ascii(s):\n",
        "    return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn')\n",
        "\n",
        "\n",
        "def preprocess_sentence_english(w):\n",
        "    w = unicode_to_ascii(w.lower().strip())\n",
        "    w = w.replace('-', ' ').replace(',', ' ')\n",
        "    \n",
        "    # creating a space between a word and the punctuation following it\n",
        "    # eg: \"he is a boy.\" => \"he is a boy .\" \n",
        "    # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n",
        "    w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
        "    w = re.sub(r'[\" \"]+', \" \", w)\n",
        "    \n",
        "    # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
        "    w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
        "    \n",
        "    w = w.rstrip().strip()\n",
        "    \n",
        "    # adding a start and an end token to the sentence\n",
        "    # so that the model know when to start and stop predicting.\n",
        "    w = '@' + w + '#'\n",
        "    return w.split()\n",
        "\n",
        "def preprocess_sentence_hindi(w):\n",
        "    w = unicode_to_ascii(w.strip())\n",
        "    w = w.replace('-', ' ').replace(',', ' ')\n",
        "    cleaned_line = ''\n",
        "    for char in w:\n",
        "        if char in hindi_alpha2index or char == ' ':\n",
        "            cleaned_line += char\n",
        "#     print(cleaned_line)\n",
        "#     cleaned_line = cleaned_line.split()\n",
        "#     print(cleaned_line)\n",
        "    cleaned_line = cleaned_line.rstrip().strip()\n",
        "    \n",
        "    # adding a start and an end token to the sentence\n",
        "    # so that the model know when to start and stop predicting.\n",
        "    cleaned_line = '@' + cleaned_line + '#'\n",
        "    return cleaned_line.split()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CMXOMW1T0bLX",
        "colab_type": "text"
      },
      "source": [
        "### Reading data from  the xml file and applying the pre-processing steps."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FY6mGkni-LGH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import xml.etree.ElementTree as ET\n",
        "def create_dataset(filename):\n",
        "\n",
        "    transliterationCorpus = ET.parse(filename).getroot()\n",
        "    lang1_words = []\n",
        "    lang2_words = []\n",
        "\n",
        "    for line in transliterationCorpus:\n",
        "                wordlist1 = preprocess_sentence_english(line[0].text) # clean English words.\n",
        "                wordlist2 = preprocess_sentence_hindi(line[1].text)# clean hindi words.\n",
        "                if len(wordlist1) != len(wordlist2):\n",
        "                    print('Skipping: ', line[0].text, ' - ', line[1].text)\n",
        "                    continue\n",
        "\n",
        "                for word in wordlist1:\n",
        "                    lang1_words.append(word)\n",
        "                for word in wordlist2:\n",
        "                    lang2_words.append(word)\n",
        "    return [lang1_words,lang2_words]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKlK5YustJ0d",
        "colab_type": "code",
        "outputId": "8c6f36ec-11eb-4cca-af9b-af88cc4e17e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "PATH = \"/content/drive/My Drive/NLP-self/Data/English_Devnagri_transliteration_data/\"\n",
        "train_data = create_dataset(PATH+'NEWS2012TrainingEnHi.xml')\n",
        "test_data = create_dataset(PATH+'NEWS2012-Testing-EnHi-1000.xml')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Skipping:  BUSHNELL'S MUSEUM  -  बुशनेल्स म्युज़ियम\n",
            "Skipping:  I^DUKAANT  -  इंदुकांत\n",
            "Skipping:  THE AUSTRALIAN/VOGEL LITERARY AWARD  -  द ऑस्ट्रेलियन/वोगेल लिट्रेरी अवार्ड\n",
            "Skipping:  Bhaalachan_dr  -  भालचन्द्र\n",
            "Skipping:  MAN OF THE YEAR/PERSON OF THE YEAR  -  मैन ऑफ द ईयर/पर्सन ऑफ द ईयर\n",
            "Skipping:  BARHARWA JUNCTION  -  बरहरवा\n",
            "Skipping:  QUEEN ANNE'S WAR  -  क्वीन एनीज वार\n",
            "Skipping:  STATE BNK TR  -  स्टेट बैंक ऑफ त्रावणकोर\n",
            "Skipping:  IN_DRAJEET  -  इन्द्रजीत\n",
            "Skipping:  SAINT FRANCIS D'ASSISI HIGH SCHOOL  -  सेंट फ्रांसिस ड‍िअस‍ीसी हाई स्कूल\n",
            "Skipping:  SHU'A  -  शुआ\n",
            "Skipping:  SOUTH ARLINGTON CHURCH OF CHRIST  -  साउथ अर्लिंग्टन\n",
            "Skipping:  I^diyaa  -  इंडिया\n",
            "Skipping:  DAI'EI  -  दैई\n",
            "Skipping:  ISMA'IL  -  इस्मा'ईल\n",
            "Skipping:  WOMEN'S LITERATURE PRIZE  -  वुमेन्स लिट्रेचर प्राइज़\n",
            "Skipping:  KING EDWARD VII  -  किंग एडवर्ड\n",
            "Skipping:  BRAJEN_DR  -  ब्रजेन्द्र\n",
            "Skipping:  DIBANG VALLEY  -  दिबंगवैली\n",
            "Skipping:  LU'LU  -  लु'लु\n",
            "Skipping:  SAINT MICHAEL'S ACADEMY, CHENNAI  -  सेंट माइकल्स एकेडमी, चेन्नई\n",
            "Skipping:  Cadbury's  -  कैडबरीज़\n",
            "Skipping:  FRANKLIN D. ROOSEVELT  -  फ्रेंकलिन डी. रूसबेल्ट\n",
            "Skipping:  SAINT STANISLAUS HIGH SCHOOL. MUMBAI  -  सेंट स्टेनिस्लॉस हाई स्कूल, मुम्बई\n",
            "Skipping:  SAINT GEORGE'S CHANNEL  -  सेंट जॉर्ज्स चैनल\n",
            "Skipping:  I^JEENIYAR  -  इंजीनियर\n",
            "Skipping:  JITEN_DR  -  जितेन्द्र\n",
            "Skipping:  APNA KAUN ?  -  अपना कौन?\n",
            "Skipping:  ORDER OF VASA  -  ऑडर ऑफ़ द वासा\n",
            "Skipping:  P'yongyang  -  पियोंगयांग\n",
            "Skipping:  SA'IRAH  -  साइराह\n",
            "Skipping:  DOROTHY CANFIELD FISHER CHILDREN'S BOOK AWARD  -  डोरोथी कैनफील्ड फिशर चिल्ड्रन बुक अवार्ड\n",
            "Skipping:  Baidu.com  -  बेदु.कॉम\n",
            "Skipping:  AZAMNAGAR ROAD  -  आज़मनगर\n",
            "Skipping:  KING GEORGE'S WAR  -  किंग जॉर्ज्स वार\n",
            "Skipping:  ALMA ASSEMBLY OF GOD'S  -  अल्मा असेंब्ली ऑफ गॉड्स\n",
            "Skipping:  CAPE TOWN  -  केपटाउन\n",
            "Skipping:  NEW ZEALAND  -  न्यूज़ीलैंड\n",
            "Skipping:  SEA OF THE HEBRIDES  -  सी ऑफ हरब्रिड्‍स\n",
            "Skipping:  RAMCOIND  -  राम्को इंड\n",
            "Skipping:  MANEE^DR  -  मणींद्र\n",
            "Skipping:  VISHVEN_DR  -  विश्वेन्द्र\n",
            "Skipping:  KELVINGROVE ART GALLERY AND MUSEUM  -  केल्व‍िनग्रोव आर्ट एण्ड म्युज़ियम\n",
            "Skipping:  AUSTRALIAN NATIONAL UNIVERSITY  -  ऑस्ट्रेलियननेशनल यूनिवर्सिटी\n",
            "Skipping:  JAHAN AARA  -  जहाँआरा\n",
            "Skipping:  NAVABHARAT FERRO ALLOYS  -  नव भारत फ़ैरो अलॉय\n",
            "Skipping:  FA'ATETE  -  फाटेट\n",
            "Skipping:  LAHI'AH  -  लहियाह\n",
            "Skipping:  WORLD ASSOCIATION OF NEWSPAPERS'S GOLDEN PEN OF FREEDOM AWARD  -  वर्ल्ड एसोसिएशन ऑफ न्युज़पेपर्स गोल्डन पेन ऑफ फ्रीडम अवार्ड\n",
            "Skipping:  RAMA LINGESHWARA  -  रामालिंगेश्वर\n",
            "Skipping:  JACOB'S WELL  -  जैकॉब्स वेल\n",
            "Skipping:  FAKHRUN NISA  -  फखरुन्निसा\n",
            "Skipping:  SA'OOD  -  सऊद\n",
            "Skipping:  DEVEN_DR  -  देवेन्द्र\n",
            "Skipping:  IN'AM  -  इनआम\n",
            "Skipping:  SHU'AA  -  शुआ\n",
            "Skipping:  OMKARNATH THAKUR  -  ओंकार नाथ ठाकुर\n",
            "Skipping:  OPENTV  -  ओपन टीवी\n",
            "Skipping:  SHAILEN_DR  -  शैलेन्द्र\n",
            "Skipping:  SAINT XAVIERS'S SCHOOL, CHANDIGARH  -  सेंट ज़ेवियर्स स्कूल, चंडीगढ़\n",
            "Skipping:  Un_manaa  -  उन्मना\n",
            "Skipping:  ENVOY COMMUNICATIONS GROUP  -  एन्वॉय कम्युनिकेशंस\n",
            "Skipping:  CHINA'S GREAT WALL MUSEUM  -  चाइनाज ग्रेट वाल म्युज़ियम\n",
            "Skipping:  SA'IM  -  सईम\n",
            "Skipping:  WAR OF THE HOLY LEAGUE  -  वार ऑफ होली लीग\n",
            "Skipping:  ABDUL MUTA'ALEE  -  अब्दुल मुताअली\n",
            "Skipping:  CHAMPION'S CUP  -  चैंपियन्स कप\n",
            "Skipping:  PRICKETT'S FORT  -  प्रिकेट्‍स फोर्ट\n",
            "Skipping:  UNICREDITO ITALIANO.  -  यूनीक्रेडिटो इटालियानो\n",
            "Skipping:  MU'ALLA  -  मुअल्ला\n",
            "Skipping:  GOVERNOR GENERAL'S AWARD  -  गवर्नर जनरल्स अवार्ड\n",
            "Skipping:  TO'ERE  -  टोएरे\n",
            "Skipping:  SUREN_DAR  -  सुरेन्दर\n",
            "Skipping:  SAINT MARY'S CONVENT INTER COLLEGE, ALLAHABAD  -  सेंट मेरीज़ कॉंन्वेंट इंटर कॉलेज, अलाहाबाद\n",
            "Skipping:  SAINT JOHN'S HIGH SCHOOL, CHANDIGARH  -  सेंट जॉन्‍स हाई स्कूल, चंडीगढ़\n",
            "Skipping:  SIR JOHN SOANE'S MUSEUM  -  सर जॉन सॉन्स म्युज़ियम\n",
            "Skipping:  Lokamaan_y  -  लोकमान्य\n",
            "Skipping:  VAPARAISO CHURCH OF CHRIST  -  व्हापरासिओ\n",
            "Skipping:  SAUJAN_Y  -  सौजन्य\n",
            "Skipping:  PARIS CHARLES DE GAULLE  -  पेरिस रॉसे चार्ल्स डे ग्यूले\n",
            "Skipping:  PARKWAY APOSTOLIC  -  पार्क वे अपोस्टोलिक\n",
            "Skipping:  Kapee^dr  -  कपींद्र\n",
            "Skipping:  E'TEMAD  -  इत्तेमाद\n",
            "Skipping:  MU'AWWIZ  -  मुआव्विज़\n",
            "Skipping:  MAUNA LOA  -  मौनालोआ\n",
            "Skipping:  HARRY S. TRUMAN  -  हैरी एस. ट्रूमेन\n",
            "Skipping:  SAINT GEORGE'S  -  सेंट जॉर्ज\n",
            "Skipping:  MCDONALD'S  -  मैकडॉनल्ड्स\n",
            "Skipping:  MU'AZZAM  -  मुअज़्ज़म\n",
            "Skipping:  MASS MUTUAL LIFE  -  मास म्युच्युअल लाइफ़ इंश्योरेंस\n",
            "Skipping:  STATS CHIPPAC  -  स्टेट्सचिपपैक\n",
            "Skipping:  JOHN F. KENNEDY  -  जॉन एफ. केनेडी\n",
            "Skipping:  NA'IL  -  नाइल\n",
            "Skipping:  NEWFOUNDLAND  -  न्यू फाउंडलैंड\n",
            "Skipping:  LONDONHEATHROW  -  लंदन हीथ्रो\n",
            "Skipping:  KING PHILIP'S WAR  -  किंग फिलिप्स वार\n",
            "Skipping:  GAJEN_DR  -  गजेन्द्र\n",
            "Skipping:  Naren_dar  -  नरेन्दर\n",
            "Skipping:  MA'MUN  -  मैमून\n",
            "Skipping:  MU'AWIYAH  -  मुआवियाह\n",
            "Skipping:  HUKUMACHAN_D  -  हुकुमचन्द\n",
            "Skipping:  VANAKAN_YAA  -  वनकन्या\n",
            "Skipping:  RETALIX  -  रेटालिक्स लि.\n",
            "Skipping:  ATINDARJEET.  -  अतिंदरजीत\n",
            "Skipping:  SRISAILAM  -  श्री शैलम\n",
            "Skipping:  COLVIN TALUQADAR'S COLLEGE, LUCKNOW  -  कॉल्व‍िन तालुकदार्स कॉलेज, लखनऊ\n",
            "Skipping:  ZE'EV PRIZE  -  ज़ेव प्राइज़\n",
            "Skipping:  KAN_HAIYAALAAL  -  कन्हैयालाल\n",
            "Skipping:  KARA-KUM  -  काराकुम\n",
            "Skipping:  WIND RIVER  -  विंडरिवर\n",
            "Skipping:  SA'ID  -  सईद\n",
            "Skipping:  HARTFORD/BRADLEY  -  हॉर्टफोर्ड/ब्रॉड्ले\n",
            "Skipping:  NETAJI SUBHASH CHANDRA BOSE  -  नेताजी सुभाषचंद्र बोस\n",
            "Skipping:  ROCKBROOK UNITED  -  रॉकब्रुक यूनाइटेड मेथोडिस्ट\n",
            "Skipping:  WALTER SCOTT  -  वॉल्टरस्कॉट\n",
            "Skipping:  COLOURPLUS FASHIONS  -  कलर प्लस फ़ैशन्स\n",
            "Skipping:  Islip/macarthur  -  इसलिप/माकॉरथूर\n",
            "Skipping:  DUMMER'S WAR  -  ड्रमर्स वार\n",
            "Skipping:  SAINT PIERRE'S EPISCOPAL  -  सेंट पिरेस एपिस्कोपाल\n",
            "Skipping:  BAL KRISHNA  -  बालकृष्णा\n",
            "Skipping:  MU'ALLIM  -  मुअल्लिम\n",
            "Skipping:  SU'AD  -  सुआह\n",
            "Skipping:  PUGACHEV'S REBELLION  -  प्यूगाचेव्स रिबेलियन\n",
            "Skipping:  Shaile^dr  -  शैलेंद्र\n",
            "Skipping:  RAAJEN_DR  -  राजेन्द्र\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q83kdZJy0n_b",
        "colab_type": "text"
      },
      "source": [
        "### review some samples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jhOoqE5viF7",
        "colab_type": "code",
        "outputId": "cec2f1c3-02f4-4f1d-e9cd-0355518ba254",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        }
      },
      "source": [
        "train_data[0][:10],train_data[1][:10]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['@raasavihaaree#',\n",
              "  '@deogan',\n",
              "  'road#',\n",
              "  '@shatrumardan#',\n",
              "  '@mahijuba#',\n",
              "  '@sabine#',\n",
              "  '@bill',\n",
              "  'cosby#',\n",
              "  '@rishta',\n",
              "  'kagaz'],\n",
              " ['@रासविहारी#',\n",
              "  '@दवगन',\n",
              "  'रोड#',\n",
              "  '@शतरमरदन#',\n",
              "  '@महिजबा#',\n",
              "  '@सबिन#',\n",
              "  '@बिल',\n",
              "  'कॉसबी#',\n",
              "  '@रिशता',\n",
              "  'कागज'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPP80gJqAKy1",
        "colab_type": "code",
        "outputId": "bc24fbd0-80b5-4d36-edd7-ca1293512376",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(test_data[0]),len(test_data[1]),len(train_data[0])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 1000, 20373)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTai5pdh02Ls",
        "colab_type": "text"
      },
      "source": [
        "### Combine the test and train data. So that we can split train and test set according to our needs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PK_KmTnZ6Ne2",
        "colab_type": "code",
        "outputId": "e2b7b2ce-e1e4-40ce-c88c-030e2b5f814b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "train_data[0].extend(test_data[0])\n",
        "train_data[1].extend(test_data[1])\n",
        "\n",
        "print(len(train_data[0]),len(train_data[1]))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "21373 21373\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mcu85hJ08Hc2",
        "colab_type": "code",
        "outputId": "2e3a002a-e5dc-407c-93f5-6a23212fe850",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "train_data[0][-1],train_data[1][-1]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('@zion#', '@जिऑन#')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JgJq_0M-yM2W",
        "colab_type": "code",
        "outputId": "6553e95e-5a16-4859-f0dc-2f424bb3f594",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(train_data[0]),len(train_data[1])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(21373, 21373)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZCcY-aS1d9B",
        "colab_type": "text"
      },
      "source": [
        "### Vocab class. This class will store word2index and index2word mapping for both language."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Pb7NniioydP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class WordIndex():\n",
        "  def __init__(self, lang):\n",
        "    self.lang = lang\n",
        "    self.word2idx = {}\n",
        "    self.idx2word = {}\n",
        "    self.vocab = set()\n",
        "    \n",
        "    self.create_index()\n",
        "    \n",
        "  def create_index(self):\n",
        "    for phrase in self.lang:\n",
        "      for l in phrase:\n",
        "        self.vocab.update(l)\n",
        "    \n",
        "    self.vocab = sorted(self.vocab)\n",
        "    \n",
        "    self.word2idx['<pad>'] = 0\n",
        "    for index, word in enumerate(self.vocab):\n",
        "      self.word2idx[word] = index + 1\n",
        "    \n",
        "    for word, index in self.word2idx.items():\n",
        "      self.idx2word[index] = word"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jY53d8l32BFy",
        "colab_type": "text"
      },
      "source": [
        "### Helper functions to create Lang vocab and  tensors from words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDeBLOoMzW1u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def max_length(tensor):\n",
        "    return max(len(t) for t in tensor)\n",
        "\n",
        "\n",
        "def load_dataset(pairs):\n",
        "\n",
        "\n",
        "    # index language using the class defined above    \n",
        "    inp_lang = WordIndex(pairs[0])\n",
        "    targ_lang = WordIndex(pairs[1])\n",
        "    \n",
        "    # Vectorize the input and target languages\n",
        "    \n",
        "    # English words\n",
        "    input_tensor = [[inp_lang.word2idx[s] for s in en] for en in pairs[0]]\n",
        "    \n",
        "    # hindi words\n",
        "    target_tensor = [[targ_lang.word2idx[s] for s in hn] for hn in pairs[1]]\n",
        "    \n",
        "    # Calculate max_length of input and output tensor\n",
        "    # Here, we'll set those to the longest sentence in the dataset\n",
        "    max_length_inp, max_length_tar = max_length(input_tensor), max_length(target_tensor)\n",
        "    \n",
        "    # Padding the input and output tensor to the maximum length\n",
        "    input_tensor = tf.keras.preprocessing.sequence.pad_sequences(input_tensor, \n",
        "                                                                 maxlen=max_length_inp,\n",
        "                                                                 padding='post')\n",
        "    \n",
        "    target_tensor = tf.keras.preprocessing.sequence.pad_sequences(target_tensor, \n",
        "                                                                  maxlen=max_length_tar, \n",
        "                                                                  padding='post')\n",
        "    \n",
        "    return input_tensor, target_tensor, inp_lang, targ_lang, max_length_inp, max_length_tar"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFHpjN3u0QGy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_tensor, target_tensor, inp_lang, targ_lang, max_length_inp, max_length_targ = load_dataset(train_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ooXuKmu62vHV",
        "colab_type": "text"
      },
      "source": [
        "### Function to convert tensor to word and print."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2icIwEi40Gi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert(lang, tensor):\n",
        "  for t in tensor:\n",
        "    if t!=0:\n",
        "      print (\"%d ----> %s\" % (t, lang.idx2word[t]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkWJ4ug94YWK",
        "colab_type": "code",
        "outputId": "fc96c129-8415-492c-f60b-9c8574e641ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "convert(inp_lang,input_tensor[-1])\n",
        "convert(targ_lang,target_tensor[-1])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3 ----> @\n",
            "29 ----> z\n",
            "12 ----> i\n",
            "18 ----> o\n",
            "17 ----> n\n",
            "1 ----> #\n",
            "2 ----> @\n",
            "21 ----> ज\n",
            "48 ----> ि\n",
            "12 ----> ऑ\n",
            "33 ----> न\n",
            "1 ----> #\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mf6M2Nvn23tu",
        "colab_type": "text"
      },
      "source": [
        "### Train and Test split."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRAS0_lV9Cbp",
        "colab_type": "code",
        "outputId": "1f2ca460-e667-44d0-da81-45fd8eb8bb1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.05)\n",
        "\n",
        "# Show length\n",
        "len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20304, 20304, 1069, 1069)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X436_KrR5qc_",
        "colab_type": "text"
      },
      "source": [
        "### Some hyper-parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPfhzW_4cN2y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BUFFER_SIZE = len(input_tensor_train)\n",
        "BATCH_SIZE = 128\n",
        "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
        "embedding_dim = 256\n",
        "units = 1024\n",
        "vocab_inp_size = len(inp_lang.word2idx)+1\n",
        "vocab_tar_size = len(targ_lang.word2idx)+1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qng8T0Yn6Jhm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5OEDecXdWq1",
        "colab_type": "code",
        "outputId": "367c8814-339b-4d9f-8d79-f01ae545178a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "example_input_batch, example_target_batch = next(iter(dataset))\n",
        "example_input_batch.shape, example_target_batch.shape"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([128, 22]), TensorShape([128, 16]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VvKZ_oXrB3ao",
        "colab_type": "text"
      },
      "source": [
        "## Let's build the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05H-mb8n8T2w",
        "colab_type": "text"
      },
      "source": [
        "### The encoder : it will consume input and produce a thought vector which will be the input of the decoder after applying attention to it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PqskC77rdnCx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.enc_units = enc_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.enc_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "\n",
        "  def call(self, x, hidden):\n",
        "#     print(type(x))\n",
        "    x = self.embedding(x)\n",
        "#     print(x.shape)\n",
        "    output, state = self.gru(x, initial_state = hidden)\n",
        "    return output, state\n",
        "\n",
        "  def initialize_hidden_state(self):\n",
        "    return tf.zeros((self.batch_sz, self.enc_units))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crfdgaFOduHk",
        "colab_type": "code",
        "outputId": "b42fd543-3c99-41aa-cd1c-69f651527342",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "# sample input\n",
        "sample_hidden = encoder.initialize_hidden_state()\n",
        "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
        "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
        "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoder output shape: (batch size, sequence length, units) (128, 22, 1024)\n",
            "Encoder Hidden state shape: (batch size, units) (128, 1024)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vtfPnPlclbR",
        "colab_type": "text"
      },
      "source": [
        "### Attention part : this model will return weights so that we feed them into decoder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cz_f1wVdwxi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BahdanauAttention(tf.keras.Model):\n",
        "  def __init__(self, units):\n",
        "    super(BahdanauAttention, self).__init__()\n",
        "    self.W1 = tf.keras.layers.Dense(units)\n",
        "    self.W2 = tf.keras.layers.Dense(units)\n",
        "    self.V = tf.keras.layers.Dense(1)\n",
        "\n",
        "  def call(self, query, values):\n",
        "    # hidden shape == (batch_size, hidden size)\n",
        "    # hidden_with_time_axis shape == (batch_size, 1, hidden size)\n",
        "    # we are doing this to perform addition to calculate the score\n",
        "    hidden_with_time_axis = tf.expand_dims(query, 1)\n",
        "\n",
        "    # score shape == (batch_size, max_length, 1)\n",
        "    # we get 1 at the last axis because we are applying score to self.V\n",
        "    # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
        "    score = self.V(tf.nn.tanh(\n",
        "        self.W1(values) + self.W2(hidden_with_time_axis)))\n",
        "\n",
        "    # attention_weights shape == (batch_size, max_length, 1)\n",
        "    attention_weights = tf.nn.softmax(score, axis=1)\n",
        "\n",
        "    # context_vector shape after sum == (batch_size, hidden_size)\n",
        "    context_vector = attention_weights * values\n",
        "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "    return context_vector, attention_weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDkWwjEOd-Ao",
        "colab_type": "code",
        "outputId": "74ee2432-e08a-4e51-d5a2-dc9e11943f80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "attention_layer = BahdanauAttention(10)\n",
        "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
        "\n",
        "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
        "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Attention result shape: (batch size, units) (128, 1024)\n",
            "Attention weights shape: (batch_size, sequence_length, 1) (128, 22, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCkKrcsMc6a-",
        "colab_type": "text"
      },
      "source": [
        "### The decoder  : calculates the probablity of next character by taking input the attention weights and encoder input."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nm06Z5ZeA_R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.dec_units = dec_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.dec_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "    self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "    # used for attention\n",
        "    self.attention = BahdanauAttention(self.dec_units)\n",
        "\n",
        "  def call(self, x, hidden, enc_output):\n",
        "    # enc_output shape == (batch_size, max_length, hidden_size)\n",
        "    context_vector, attention_weights = self.attention(hidden, enc_output)\n",
        "\n",
        "\n",
        "    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
        "    x = self.embedding(x)\n",
        "\n",
        "    # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
        "    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "\n",
        "    # passing the concatenated vector to the GRU\n",
        "    output, state = self.gru(x)\n",
        "\n",
        "    # output shape == (batch_size * 1, hidden_size)\n",
        "    output = tf.reshape(output, (-1, output.shape[2]))\n",
        "\n",
        "    # output shape == (batch_size, vocab)\n",
        "    x = self.fc(output)\n",
        "\n",
        "    return x, state, attention_weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJsui7IgeE8U",
        "colab_type": "code",
        "outputId": "12461595-536c-494a-e6e6-3e0253fbaff3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "sample_decoder_output, _, _ = decoder(tf.random.uniform((128, 1)),\n",
        "                                      sample_hidden, sample_output)\n",
        "\n",
        "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Decoder output shape: (batch_size, vocab size) (128, 55)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHebK0P-eHUL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "\n",
        "def loss_function(real, pred):\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  loss_ = loss_object(real, pred)\n",
        "\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "  loss_ *= mask\n",
        "\n",
        "  return tf.reduce_mean(loss_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRF4wAGWdUGs",
        "colab_type": "text"
      },
      "source": [
        "### adding checkpoints to store the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hhETH5heO8d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
        "                                 encoder=encoder,\n",
        "                                 decoder=decoder)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bK2CVaJNdhTg",
        "colab_type": "text"
      },
      "source": [
        "### Training step function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ok00MPnQeQ5o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def train_step(inp, targ, enc_hidden):\n",
        "  loss = 0\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
        "\n",
        "    dec_hidden = enc_hidden\n",
        "\n",
        "    dec_input = tf.expand_dims([targ_lang.word2idx['@']] * BATCH_SIZE, 1)\n",
        "\n",
        "    # Teacher forcing - feeding the target as the next input\n",
        "    for t in range(1, targ.shape[1]):\n",
        "      # passing enc_output to the decoder\n",
        "      predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
        "\n",
        "      loss += loss_function(targ[:, t], predictions)\n",
        "\n",
        "      # using teacher forcing\n",
        "      dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "\n",
        "  batch_loss = (loss / int(targ.shape[1]))\n",
        "\n",
        "  variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "\n",
        "  gradients = tape.gradient(loss, variables)\n",
        "\n",
        "  optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "  return batch_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3eZL_pnxdlCR",
        "colab_type": "text"
      },
      "source": [
        "### Training loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kq5pHgRkelfL",
        "colab_type": "code",
        "outputId": "db8d21df-60ba-40d4-8b61-ee263281e1d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "EPOCHS = 25\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  start = time.time()\n",
        "\n",
        "  enc_hidden = encoder.initialize_hidden_state()\n",
        "  total_loss = 0\n",
        "\n",
        "  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
        "    batch_loss = train_step(inp, targ, enc_hidden)\n",
        "    total_loss += batch_loss\n",
        "\n",
        "    if batch % 100 == 0:\n",
        "        print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                                     batch,\n",
        "                                                     batch_loss.numpy()))\n",
        "  # saving (checkpoint) the model every 2 epochs\n",
        "  if (epoch + 1) % 2 == 0:\n",
        "    checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "  print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                      total_loss / steps_per_epoch))\n",
        "  print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <bound method Encoder.call of <__main__.Encoder object at 0x7f5b94fba470>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method Encoder.call of <__main__.Encoder object at 0x7f5b94fba470>>, which Python reported as:\n",
            "  def call(self, x, hidden):\n",
            "#     print(type(x))\n",
            "    x = self.embedding(x)\n",
            "#     print(x.shape)\n",
            "    output, state = self.gru(x, initial_state = hidden)\n",
            "    return output, state\n",
            "\n",
            "This may be caused by multiline strings or comments not indented at the same level as the code.\n",
            "WARNING: Entity <bound method Encoder.call of <__main__.Encoder object at 0x7f5b94fba470>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method Encoder.call of <__main__.Encoder object at 0x7f5b94fba470>>, which Python reported as:\n",
            "  def call(self, x, hidden):\n",
            "#     print(type(x))\n",
            "    x = self.embedding(x)\n",
            "#     print(x.shape)\n",
            "    output, state = self.gru(x, initial_state = hidden)\n",
            "    return output, state\n",
            "\n",
            "This may be caused by multiline strings or comments not indented at the same level as the code.\n",
            "WARNING:tensorflow:Entity <bound method Encoder.call of <__main__.Encoder object at 0x7f5b94fba470>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method Encoder.call of <__main__.Encoder object at 0x7f5b94fba470>>, which Python reported as:\n",
            "  def call(self, x, hidden):\n",
            "#     print(type(x))\n",
            "    x = self.embedding(x)\n",
            "#     print(x.shape)\n",
            "    output, state = self.gru(x, initial_state = hidden)\n",
            "    return output, state\n",
            "\n",
            "This may be caused by multiline strings or comments not indented at the same level as the code.\n",
            "WARNING: Entity <bound method Encoder.call of <__main__.Encoder object at 0x7f5b94fba470>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method Encoder.call of <__main__.Encoder object at 0x7f5b94fba470>>, which Python reported as:\n",
            "  def call(self, x, hidden):\n",
            "#     print(type(x))\n",
            "    x = self.embedding(x)\n",
            "#     print(x.shape)\n",
            "    output, state = self.gru(x, initial_state = hidden)\n",
            "    return output, state\n",
            "\n",
            "This may be caused by multiline strings or comments not indented at the same level as the code.\n",
            "Epoch 1 Batch 0 Loss 1.2116\n",
            "Epoch 1 Batch 100 Loss 0.8421\n",
            "Epoch 1 Loss 0.8650\n",
            "Time taken for 1 epoch 79.39243078231812 sec\n",
            "\n",
            "Epoch 2 Batch 0 Loss 0.6125\n",
            "Epoch 2 Batch 100 Loss 0.2837\n",
            "Epoch 2 Loss 0.3299\n",
            "Time taken for 1 epoch 54.88135600090027 sec\n",
            "\n",
            "Epoch 3 Batch 0 Loss 0.1900\n",
            "Epoch 3 Batch 100 Loss 0.2330\n",
            "Epoch 3 Loss 0.1918\n",
            "Time taken for 1 epoch 54.877965688705444 sec\n",
            "\n",
            "Epoch 4 Batch 0 Loss 0.1784\n",
            "Epoch 4 Batch 100 Loss 0.1419\n",
            "Epoch 4 Loss 0.1501\n",
            "Time taken for 1 epoch 55.13626718521118 sec\n",
            "\n",
            "Epoch 5 Batch 0 Loss 0.1410\n",
            "Epoch 5 Batch 100 Loss 0.1302\n",
            "Epoch 5 Loss 0.1244\n",
            "Time taken for 1 epoch 54.853145360946655 sec\n",
            "\n",
            "Epoch 6 Batch 0 Loss 0.1182\n",
            "Epoch 6 Batch 100 Loss 0.0893\n",
            "Epoch 6 Loss 0.1042\n",
            "Time taken for 1 epoch 55.151548624038696 sec\n",
            "\n",
            "Epoch 7 Batch 0 Loss 0.0890\n",
            "Epoch 7 Batch 100 Loss 0.0863\n",
            "Epoch 7 Loss 0.0924\n",
            "Time taken for 1 epoch 54.83919668197632 sec\n",
            "\n",
            "Epoch 8 Batch 0 Loss 0.0761\n",
            "Epoch 8 Batch 100 Loss 0.0907\n",
            "Epoch 8 Loss 0.0783\n",
            "Time taken for 1 epoch 55.62103295326233 sec\n",
            "\n",
            "Epoch 9 Batch 0 Loss 0.0574\n",
            "Epoch 9 Batch 100 Loss 0.0683\n",
            "Epoch 9 Loss 0.0688\n",
            "Time taken for 1 epoch 55.188676834106445 sec\n",
            "\n",
            "Epoch 10 Batch 0 Loss 0.0547\n",
            "Epoch 10 Batch 100 Loss 0.0578\n",
            "Epoch 10 Loss 0.0598\n",
            "Time taken for 1 epoch 55.367626905441284 sec\n",
            "\n",
            "Epoch 11 Batch 0 Loss 0.0525\n",
            "Epoch 11 Batch 100 Loss 0.0963\n",
            "Epoch 11 Loss 0.0676\n",
            "Time taken for 1 epoch 55.20212268829346 sec\n",
            "\n",
            "Epoch 12 Batch 0 Loss 0.0746\n",
            "Epoch 12 Batch 100 Loss 0.0721\n",
            "Epoch 12 Loss 0.0657\n",
            "Time taken for 1 epoch 55.450058460235596 sec\n",
            "\n",
            "Epoch 13 Batch 0 Loss 0.0459\n",
            "Epoch 13 Batch 100 Loss 0.0463\n",
            "Epoch 13 Loss 0.0463\n",
            "Time taken for 1 epoch 55.11216354370117 sec\n",
            "\n",
            "Epoch 14 Batch 0 Loss 0.0416\n",
            "Epoch 14 Batch 100 Loss 0.0252\n",
            "Epoch 14 Loss 0.0347\n",
            "Time taken for 1 epoch 55.29107069969177 sec\n",
            "\n",
            "Epoch 15 Batch 0 Loss 0.0259\n",
            "Epoch 15 Batch 100 Loss 0.0307\n",
            "Epoch 15 Loss 0.0286\n",
            "Time taken for 1 epoch 55.05149698257446 sec\n",
            "\n",
            "Epoch 16 Batch 0 Loss 0.0255\n",
            "Epoch 16 Batch 100 Loss 0.0262\n",
            "Epoch 16 Loss 0.0267\n",
            "Time taken for 1 epoch 55.3773353099823 sec\n",
            "\n",
            "Epoch 17 Batch 0 Loss 0.0205\n",
            "Epoch 17 Batch 100 Loss 0.0222\n",
            "Epoch 17 Loss 0.0236\n",
            "Time taken for 1 epoch 55.05522418022156 sec\n",
            "\n",
            "Epoch 18 Batch 0 Loss 0.0152\n",
            "Epoch 18 Batch 100 Loss 0.0313\n",
            "Epoch 18 Loss 0.0305\n",
            "Time taken for 1 epoch 55.386202812194824 sec\n",
            "\n",
            "Epoch 19 Batch 0 Loss 0.0194\n",
            "Epoch 19 Batch 100 Loss 0.0265\n",
            "Epoch 19 Loss 0.0282\n",
            "Time taken for 1 epoch 55.05883550643921 sec\n",
            "\n",
            "Epoch 20 Batch 0 Loss 0.0369\n",
            "Epoch 20 Batch 100 Loss 0.0274\n",
            "Epoch 20 Loss 0.0247\n",
            "Time taken for 1 epoch 55.365275859832764 sec\n",
            "\n",
            "Epoch 21 Batch 0 Loss 0.0138\n",
            "Epoch 21 Batch 100 Loss 0.0169\n",
            "Epoch 21 Loss 0.0180\n",
            "Time taken for 1 epoch 55.06544470787048 sec\n",
            "\n",
            "Epoch 22 Batch 0 Loss 0.0125\n",
            "Epoch 22 Batch 100 Loss 0.0126\n",
            "Epoch 22 Loss 0.0148\n",
            "Time taken for 1 epoch 55.298781394958496 sec\n",
            "\n",
            "Epoch 23 Batch 0 Loss 0.0196\n",
            "Epoch 23 Batch 100 Loss 0.0186\n",
            "Epoch 23 Loss 0.0137\n",
            "Time taken for 1 epoch 55.16735529899597 sec\n",
            "\n",
            "Epoch 24 Batch 0 Loss 0.0220\n",
            "Epoch 24 Batch 100 Loss 0.0118\n",
            "Epoch 24 Loss 0.0128\n",
            "Time taken for 1 epoch 55.325804710388184 sec\n",
            "\n",
            "Epoch 25 Batch 0 Loss 0.0126\n",
            "Epoch 25 Batch 100 Loss 0.0727\n",
            "Epoch 25 Loss 0.0383\n",
            "Time taken for 1 epoch 55.02675151824951 sec\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDr6dH_Q-EA1",
        "colab_type": "text"
      },
      "source": [
        "### Evaluation function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnAodH2Ymg6u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(sentence):\n",
        "    attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
        "\n",
        "    sentence = preprocess_sentence_english(sentence)[0]\n",
        "\n",
        "    inputs = [inp_lang.word2idx[i] for i in sentence]\n",
        "#     print(inputs)\n",
        "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
        "                                                           maxlen=max_length_inp,\n",
        "                                                           padding='post')\n",
        "#     print(inputs)\n",
        "    inputs = tf.convert_to_tensor(inputs)\n",
        "\n",
        "    result = ''\n",
        "\n",
        "    hidden = [tf.zeros((1, units))]\n",
        "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
        "\n",
        "    dec_hidden = enc_hidden\n",
        "    dec_input = tf.expand_dims([targ_lang.word2idx['@']], 0)\n",
        "\n",
        "    for t in range(max_length_targ):\n",
        "        predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
        "                                                             dec_hidden,\n",
        "                                                             enc_out)\n",
        "\n",
        "        # storing the attention weights to plot later on\n",
        "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "        attention_plot[t] = attention_weights.numpy()\n",
        "\n",
        "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "\n",
        "        result += targ_lang.idx2word[predicted_id] + ' '\n",
        "\n",
        "        if targ_lang.idx2word[predicted_id] == '#':\n",
        "            return result, sentence, attention_plot\n",
        "\n",
        "        # the predicted ID is fed back into the model\n",
        "        dec_input = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "    return result, sentence, attention_plot"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C71nUSWYt3xN",
        "colab_type": "text"
      },
      "source": [
        "### Function to plot attention weights."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bptdnTqMpbWd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# function for plotting the attention weights\n",
        "def plot_attention(attention, sentence, predicted_sentence):\n",
        "#     print(predicted_sentence)\n",
        "    fig = plt.figure(figsize=(10,10))\n",
        "    ax = fig.add_subplot(1, 1, 1)\n",
        "    ax.matshow(attention, cmap='viridis')\n",
        "\n",
        "    fontdict = {'fontsize': 14}\n",
        "\n",
        "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
        "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
        "\n",
        "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZuv-bfEt7-b",
        "colab_type": "text"
      },
      "source": [
        "### Function to transliterate a given word"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHsmy5itqt36",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def transliterate(sentence):\n",
        "    result, sentence, attention_plot = evaluate(sentence)\n",
        "\n",
        "    print('Input: %s' % (sentence))\n",
        "    print('Predicted translation: {}'.format(''.join(result.split(' '))))\n",
        "\n",
        "\n",
        "    result = unicode_to_ascii(result)    \n",
        "    attention_plot = attention_plot[:len(result.split(' ')), :len(list(sentence))]\n",
        "    plot_attention(attention_plot, list(sentence), result.split(' '))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ifF3zBkqvoF",
        "colab_type": "code",
        "outputId": "a4831fdf-b4c6-40b6-8934-7557e557bbdb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# restoring the latest checkpoint in checkpoint_dir\n",
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f5ae44d9128>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9QeTSl_qyAI",
        "colab_type": "code",
        "outputId": "74df511b-4560-4285-fe69-689c2528509f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        }
      },
      "source": [
        "transliterate('Sourabh')"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: @sourabh#\n",
            "Predicted translation: सौरभ#\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlIAAAGaCAYAAADEjK03AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwJCQAgAY+n8S5oRx3cME/gAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TB14dsZrq62o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598
        },
        "outputId": "d016bb4d-c979-482c-9797-c4d24170b4f0"
      },
      "source": [
        "transliterate('monalisha')"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: @monalisha#\n",
            "Predicted translation: मोनालिशा#\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlIAAAIiCAYAAAAD/SayAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}